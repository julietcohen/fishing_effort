---
title: "improved_loop"
author: "Juliet"
date: "11/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(here)
library(tidyverse)
library(janitor)
library(lubridate)
library(broom)
library(forecast)
library(purrr)
library(gt)
```

```{r}
data = read_csv(here('data', 'fishing-vessels-v2.csv'))
```
Initial data wrangling

```{r}
# clean the data, selecting only relevant column of fishing hours and taking the means by year for each country

effort_trends <- data %>% 
  select(flag_gfw, 
         fishing_hours_2012,
         fishing_hours_2013,
         fishing_hours_2014,
         fishing_hours_2015,
         fishing_hours_2016,
         fishing_hours_2017,
         fishing_hours_2018,
         fishing_hours_2019,
         fishing_hours_2020) %>% 
  group_by(flag_gfw) %>% 
  summarize("2012" = mean(fishing_hours_2012, na.rm = TRUE),
            "2013" = mean(fishing_hours_2013, na.rm = TRUE),
            "2014" = mean(fishing_hours_2014, na.rm = TRUE),
            "2015" = mean(fishing_hours_2015, na.rm = TRUE),
            "2016" = mean(fishing_hours_2016, na.rm = TRUE),
            "2017" = mean(fishing_hours_2017, na.rm = TRUE),
            "2018" = mean(fishing_hours_2018, na.rm = TRUE),
            "2019" = mean(fishing_hours_2019, na.rm = TRUE),
            "2020" = mean(fishing_hours_2020, na.rm = TRUE))

```

Determine which year is the best start year for the linear regression by finding the year with the lest NA values (because in our for loop, we will multiply the slope coefficient of each country's model by the same numerical value for each country when predicting their 2020 fishing effort, so we need all countries to have the same start year of data)

```{r}
# which column has the least NA values? We will use this to determine which year is the best start year for our linear regression
sum(is.na(effort_trends$"2012"))
sum(is.na(effort_trends$"2013"))
sum(is.na(effort_trends$"2014"))
sum(is.na(effort_trends$"2015"))
sum(is.na(effort_trends$"2016"))
sum(is.na(effort_trends$"2017"))
# 2017 has the least NA values, so we will remove all countries that dont have data for 2017
```

Turn the data into Tidy format so we can run linear regressions over the years, and only include fishing effort for 2017-2019 because we want to regress over those years only

```{r}
# change it to tidy format, and remove all NA values, and take out the year 2020 because we want to compare what we would EXPECT in 2020 based on what we saw in 2012-2019

effort_trends_tidy_no_na = effort_trends %>%
  select(flag_gfw, "2017":"2019") %>% 
  pivot_longer(cols = ("2017":"2019"),
               names_to = "year",
               values_to = "mean_effort") %>% 
  filter(!is.na(mean_effort),
         !is.na(flag_gfw))
```

Remove all countries that only occur once, because we need at least 2 years of fishing effort data per country to run a linear model for each country.

```{r}
# define day as Jan 1 so that when we convert the year to a date we get the first of the year so the plot looks better later on! Otherwise, R will paste TODAY'S date at the end of each year, which will skew the x axis when we plot later

month_day <- "-01-01"
effort_trends_tidy_no_na_date <- effort_trends_tidy_no_na %>% 
  mutate(year = paste0(year, month_day))

# remove those countries from the dataframe
countries_clean <- effort_trends_tidy_no_na_date %>% 
  group_by(flag_gfw) %>%
  filter(n()>1) %>% 
  mutate(year = as.Date(year, format = "%Y-%m-%d"))

# 83 coutnries remain in this dataset
```

Run a simple linear regression for just one country, as a test. Plot it to visualize the fishing effort trend.

```{r}
# ARG = Argentina 
arg_data <- countries_clean %>% 
  filter(flag_gfw == "ARG")

class(arg_data$year)

# run a linear model on a single country that increased fishing effort over time
arg_model = lm(mean_effort ~ year, data = arg_data)
summary(arg_model)

# adjust the min and max values for the y-axis so that they are multiples of 10 and encompass all the mean_effort numbers, multiples of 10 are easier for the reader to comprehend quickly
max_y_arg = round(max(arg_data$mean_effort+5), 0)
max_y_arg
min_y_arg = round(min(arg_data$mean_effort-9), 0)
min_y_arg

arg_plot <- ggplot(data = arg_data, aes(x = year, y = mean_effort, color = year)) +
   geom_point(size = 4,
              color = "firebrick",
              shape = 11) +
   geom_line(data = augment(arg_model),
             aes(y = .fitted),
             color = "orange",
             size = 2) + 
   scale_x_date(date_labels = "%Y",
                date_breaks = "1 year") +
   ggtitle("Argentina's Fishing Effort from 2017-2019") +
   xlab("Year") + 
   ylab("Mean Fishing Hours") +
   theme(panel.background = element_blank(),
         axis.title.x = element_text(color = "black", size = 15),
         axis.text.x = element_text(face = "bold", color = "black", size = 13),
         axis.title.y = element_text(color = "black", size = 15),
         axis.text.y = element_text(face = "bold", color = "black", size = 8),
         plot.title = element_text(color="black", size = 17, face="bold")) +
   scale_y_continuous(breaks = seq(min_y_arg, max_y_arg, by = 10))

arg_plot
```

Look at another country with a negative intercept (the Caribbean Netherlands) to see what that data looks like.

```{r}
can_data <- countries_clean %>% 
  filter(flag_gfw == "CAN") #%>% 

# run a linear model on a single country that decreased fishing effort over time
can_model = lm(mean_effort ~ year, data = can_data)
summary(can_model)

max_y_can = round(max(can_data$mean_effort+4), 0)
max_y_can
min_y_can = round(min(can_data$mean_effort-3), 0)
min_y_can

ggplot(data = can_data, aes(x = year, y = mean_effort, color = year)) +
   geom_point(size = 4, 
              color = "firebrick",
              shape = 11) +
   geom_line(data = augment(can_model),
             aes(y = .fitted),
             color = "orange",
             size = 2) + 
   scale_x_date(date_labels = "%Y",
                date_breaks = "1 year") +
   ggtitle("Canada's Fishing Effort from 2017-2019") +
   xlab("Year") + 
   ylab("Mean Fishing Hours") +
   theme(panel.background = element_blank(),
   axis.title.x = element_text(color = "black", size = 15),
         axis.text.x = element_text(face = "bold", color = "black", size = 13),
         axis.title.y = element_text(color = "black", size = 15),
         axis.text.y = element_text(face = "bold", color = "black", size = 8),
         plot.title = element_text(color="black", size = 17, face="bold")) +
   scale_y_continuous(breaks = seq(min_y_can, max_y_can, by = 10))
```

Use the `sapply()` function to iterate through all the countries and run a linear model. Then, concatenate those linear model summaries using `lapply()`.

```{r}
countries_clean %>% 
  group_by(flag_gfw) %>% 
  do(data.frame(., as.list(coef(lm(mean_effort~year, .)))))

# try to adjust the code that worked earlier to be like this code
models <- sapply(unique(as.character(countries_clean$flag_gfw)),
                 function(country)as.numeric(coef(lm(mean_effort~year, countries_clean, subset = (flag_gfw == country)))),
                 simplify = FALSE, USE.NAMES = TRUE)
models[[4]]
# retunrs just that country's coefficients
#models$ARG[1]
#countries_lm_summaries <- lapply(models, summary)
#countries_lm_summaries
models
```

```{r}
prediction_data = NULL;
for (i in 1:length(models)) {
  predicted_effort_2020 <- models[[i]][1] + models[[i]][2]*3
  prediction_data <- rbind(prediction_data, predicted_effort_2020)
  print(paste0("In 2020, the predicted fishing hours is ", predicted_effort_2020))
}
```
Combine the predicted 2020 fishing effort data with the actual 2020 fishing effort data to compare by country.

```{r}
# figure out which countries were used in the for loop so we can get the actual 2020 effort data for those countries only
countries_clean_unique <- countries_clean %>% 
  group_by(flag_gfw) %>%
  slice_head(n = 1)

# set these countries as a vector so we can subset the effort_trends data to only include those countries
countries_to_compare <- unique(countries_clean_unique$flag_gfw)
countries_to_compare
  
# ensure that there are 83 rows in both datasets
nrow(countries_clean_unique)
nrow(prediction_data)

# set the effort trends data to only include those countries
comparison_2020 <- effort_trends %>% 
  select(flag_gfw, "2020") %>%
  rename(actual_2020 = "2020") %>% 
  filter(str_detect(flag_gfw, paste(countries_to_compare, collapse="|"))) %>% 
  cbind(prediction_data) %>% 
  rename(prediction_2020 = prediction_data) %>% 
  filter(actual_2020 != "NaN")
# I made sure to remove the NAN values from the countries that did not have actual data for 2020 AFTER I USED cbind() because I wanted to bind the actual 2020 data to the corresponding rows with the predicted data first or else the alignment would yield incorrect data
```

```{r}
# remove all negative values in the predicted column, the linear regression did not fit this data well
comparison_2020_pos <- comparison_2020 %>% 
  filter(prediction_2020 >= 0)

# take the difference between the actual and the predicted columns
comparison_2020_pos <- comparison_2020_pos %>% 
  mutate(difference = prediction_2020 - actual_2020) %>% 
  mutate(change_direc = case_when(
    difference > 0 ~ "fished LESS than trend",
    difference < 0 ~ "fished MORE than trend"))
```


Do a hypothesis test on the difference between the predicted mean and the average mean.

**Null Hypothesis:** There is no difference between the predicted country-specific predicted fishing effort in 2020 and the actual country-specific fishing effort in 2020.
**Alternative Hypothesis:** There is a difference between the predicted country-specific predicted fishing effort in 2020 and the actual country-specific fishing effort in 2020. Because of the pandemic in 2020, I predict that fishing effort decreased, meaning that the actual country-specific fishing effort is less than the predicted country-specific fishing effort.


Convert the data to **Tidy format** so we are able to run a ttest:
```{r}
comparison_tidy <- comparison_2020_pos %>% 
  pivot_longer(cols = ("actual_2020":"prediction_2020"),
               names_to = "actual_or_predicted",
               values_to = "mean_effort")
```

```{r}
ttest = t.test(mean_effort ~ actual_or_predicted, data = comparison_tidy, conf.level = 0.95)
ttest
```
The p-value is 0.0004962, and 0.0004962 < 0.05, so we can reject our null hypothesis that there is no difference between the predicted country-specific predicted fishing effort in 2020 and the actual country-specific fishing effort in 2020.

## consider making map with countries red if they inc and green if they decreased

This table shows the countries that increased their 2020 fishing effort relative to their trend leading up to 2020, versus those that decreased their 2020 fishing effort relative to their trend leading up to 2020.
```{r}
#table_data <- comparison_tidy %>% 
#  mutate(bad_countries = filter(change_direc == fished_more_than_trend),
#         good_countries = filter(change_direc == fished_less_than_trend))

# bad_countries = comparison_tidy %>% 
#   filter(change_direc == "fished_more_than_trend")
# 
# bad_countries_list <- as.list(unique(bad_countries$flag_gfw))
# #bad_countries_list
# 
# good_countries = comparison_tidy %>% 
#   filter(change_direc == "fished_less_than_trend")
# 
# good_countries_list <- as.list(unique(good_countries$flag_gfw))
#good_countries_list

# make a datafame from these lists

#countries_good_bad_df <- as.data.frame(,
#                           col.names = c("Numbers", "Letters", "Words"))

#good_bad_df <- do.call(rbind, Map(data.frame, good = good_countries_list, bad = bad_countries_list))
# this repeats the vlaues in the good col to match # of rows in the bad col...not good

# make a table from these lists

# inc_dec_table <- gt() %>%
#   tab_header(
#     title = "Which countries increased or decreased 2020 fishing effort relative to their trend?"
#   ) %>%
#   fmt_passthrough(
#     columns = vars(bad_countries_list)
#   ) %>%
#   fmt_passthrough(
#     columns = vars(bad_countries_list)
#   ) %>%
 # fmt_number(
 #   columns = vars(median),
 #   decimals = 4
 # ) %>% 
 # cols_label(quantile = "Quantile" , mean = "Mean")
```
```{r}
# convert the comparison_tidy data to a table

# first, rearrange the columns
comparison_data_rearranged <- comparison_tidy[, c(1, 5, 4, 2, 3)]

title = md("**Penguin Data Summary**")

# make a kable table
good_bad_table <- comparison_data_rearranged %>% 
  gt() %>%
  tab_header(
    title = md("**Which countries increased or decreased 2020 fishing effort relative to their trend?**")
  ) %>%
  fmt_passthrough(
    columns = vars(flag_gfw)
  ) %>%
  fmt_number(
  columns = vars(mean_effort)
  ) %>% 
  fmt_passthrough(
    columns = vars(actual_or_predicted)
  ) %>%
  fmt_number(
  columns = vars(difference)
  ) %>%
  fmt_passthrough(
    columns = vars(change_direc)
  ) %>%
  cols_label(flag_gfw = "Country Code" , 
           mean_effort = "Mean Fishing Hours in 2020",
           actual_or_predicted = "Actual or Predicted 2020 Effort",
           difference = "Difference: Prediction - Actual",
           change_direc = "Fishing Effort Relative to Trend") %>% 
  tab_style(
    style = list(
      cell_fill(color = "chartreuse2"),
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      columns = vars(flag_gfw, mean_effort, actual_or_predicted, difference, change_direc),
      rows = change_direc == "fished LESS than trend")
  ) %>% 
  tab_style(
    style = list(
      cell_fill(color = "brown2"),
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      columns = vars(flag_gfw, mean_effort, actual_or_predicted, difference, change_direc),
      rows = change_direc == "fished MORE than trend")
  ) %>% 
  tab_source_note(source_note = "Data Source: Global Fishing Watch: https://globalfishingwatch.org/datasets-and-code/") %>%
  opt_align_table_header(align = "center") %>% 
  cols_width(
    flag_gfw ~ px(90),
    mean_effort ~ px(140),
    actual_or_predicted ~ px(125),
    difference ~ px(240),
    change_direc ~ px(220)
  ) %>% 
  cols_align(align = "center")


good_bad_table

```









