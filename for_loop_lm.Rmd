---
title: "for_loop_lm"
author: "Juliet"
date: "11/20/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(here)
library(tidyverse)
library(janitor)
library(lubridate)
library(broom)
library(forecast)
library(purrr)
```

```{r}
data = read_csv(here('data', 'fishing-vessels-v2.csv'))

nrow_raw = nrow(data)
nrow_raw
```

Look at the countries in this dataset as well as summary stats for fishing hours in 2020

```{r}
raw_countries = unique(data$flag_gfw)
raw_countries
```
Look at fishing effort by country in 2020 and the min and max effort by country
```{r}
fishing_eff_20 <- data %>% 
  filter(fishing_hours_2020 != "NA")

fishing_eff_20_country <- aggregate(fishing_eff_20$fishing_hours_2020, by = list(country=fishing_eff_20$flag_gfw), FUN=sum) %>% 
  mutate(fishing_hours = x) %>% 
  select(country, fishing_hours)

# max value of fishing hours in 2020 by 1 country:
max_hrs_20 <- max(fishing_eff_20_country$fishing_hours)
min_hrs_20 <- min(fishing_eff_20_country$fishing_hours)

min_max_country_2020 = fishing_eff_20_country %>% 
  filter(fishing_hours == max_hrs_20 | fishing_hours == min_hrs_20)
min_max_country_2020 #CHN, JAM

country_graph <- ggplot(fishing_eff_20_country, aes(x = country, y = fishing_hours)) +
  geom_point()

country_graph
```

Look at the difference in fishing hours from 2019-2020 by country

```{r}
# filter the data to only include country, fishing hours for 19-20, and the diff btw those years
data_2019_2020 <- data %>% 
  select(flag_gfw, fishing_hours_2019, fishing_hours_2020) %>% 
  filter(fishing_hours_2019 != "NA" & fishing_hours_2020 != "NA") %>% 
  mutate(diff_19_20 = fishing_hours_2020 - fishing_hours_2019)

# aggregate difference in hours by country

change_effort_19_20 <- aggregate(data_2019_2020$diff_19_20, by = list(country=data_2019_2020$flag_gfw), FUN=sum) %>%
  mutate(fishing_hours_change = x) %>% 
  select(country, fishing_hours_change)

# which countries changed their effort the most and least from 19 --> 20?

max_change_eff <- max(data_2019_2020$diff_19_20)
min_change_eff <- min(data_2019_2020$diff_19_20)

min_max_change_eff = data_2019_2020 %>% 
  filter(diff_19_20 == max_change_eff | diff_19_20 == min_change_eff)
min_max_change_eff

# max change = China: +6411.61 hours from 20129 --> 2020
# min change = Taiwan: - 6637.94 hours from 2019 --> 2020
```
Take the mean of fishing hours by year, sorted by country, removing all NA values
```{r}
effort_trends <- data %>% 
  select(flag_gfw, 
         fishing_hours_2012,
         fishing_hours_2013,
         fishing_hours_2014,
         fishing_hours_2015,
         fishing_hours_2016,
         fishing_hours_2017,
         fishing_hours_2018,
         fishing_hours_2019,
         fishing_hours_2020) %>% 
  group_by(flag_gfw) %>% 
  summarize("2012" = mean(fishing_hours_2012, na.rm = TRUE),
            "2013" = mean(fishing_hours_2013, na.rm = TRUE),
            "2014" = mean(fishing_hours_2014, na.rm = TRUE),
            "2015" = mean(fishing_hours_2015, na.rm = TRUE),
            "2016" = mean(fishing_hours_2016, na.rm = TRUE),
            "2017" = mean(fishing_hours_2017, na.rm = TRUE),
            "2018" = mean(fishing_hours_2012, na.rm = TRUE),
            "2019" = mean(fishing_hours_2012, na.rm = TRUE),
            "2020" = mean(fishing_hours_2020, na.rm = TRUE))

# change it to tidy format, and remove all NA values, and take out the year 2020 because we want to compare what we would EXPECT in 2020 based on what we saw in 2012-2019

effort_trends_tidy_no_na = effort_trends %>%
  select(flag_gfw, "2012":"2019") %>% 
  pivot_longer(cols = ("2012":"2019"),
               names_to = "year",
               values_to = "mean_effort") %>% 
  filter(!is.na(mean_effort))

# prepare the data for the linear regressions on each country by removing all countries that only have 1 year entry, because we need at least 2 years of mean fishing effort to establish a linear model

# which countries only have data for 1 year?

single_yr_countries <- effort_trends_tidy_no_na %>%
    group_by(flag_gfw) %>%
    filter(n() == 1)
single_yr_countries

# remove those countries from the dataframe before running the linear model

loop_data <- effort_trends_tidy_no_na %>% 
  filter(flag_gfw != "CHE" & flag_gfw != "CYM" & flag_gfw != "CZE" & flag_gfw != "DJI" & flag_gfw != "GNB" & flag_gfw != "JOR" & flag_gfw != "LSO" & flag_gfw != "NGA" & flag_gfw != "NIU" & flag_gfw != "TCD" & flag_gfw != "TON" & flag_gfw != "TUN" & flag_gfw != "WLF")
```

Run a linear regression on one country as a test, to see if returns what we would expect
```{r}
abw_data <- loop_data %>% 
  filter(flag_gfw == "ABW")

# test lm model with NA's
abw_model = lm(mean_effort ~ year, data = abw_data)
summary(abw_model)
```


Program a for loop to run a linear regression on each country with at least 2 years of data from 
```{r loop with years as categories}
# make a list of all unique countries in the flag_gfw column because we want to run a linear regression on each country, not on each row

country = unique(loop_data$flag_gfw)

# run the linear regression as a loop on each country

for (i in 1:length(country)) {
  subset_data <- subset(loop_data, flag_gfw == country[i])
  model_summary <- summary(lm(mean_effort ~ year, data = subset_data))
  print(model_summary)
}
```
Adjust the linear model to run a regression over **time** by country, but first test the process on just one country

```{r as date}
# run a test on just one country
abw_data <- abw_data %>%
  mutate(year = as.Date(year, format = "%Y"))
# year cannot be a date, needs to have days, so R just attached the same random day to each year
class(abw_data$year)

# test lm model with NA's
abw_model = lm(mean_effort ~ year, data = abw_data)
summary(abw_model)

# # plot Aruba's fishing effort from 2012-2019 with the fitted line on top of the raw data
 ggplot(data = abw_data, aes(x = year, y = mean_effort, color = year)) +
   geom_point() +
   geom_line(data = augment(abw_model), aes(y = .fitted, color = year)) + 
   labs(x = "Year",
        y = "Mean Fishing Hours")
```
```{r}
# predict Aruba's fishing hours in 2019 and 2020
# the formula is: fishing_hours = 3230.04309 + (-0.17823)*(year)

# create a new column to hold the model's predicted values for Aruba's fishing hours for 2012-2019, just to check out how the predict function's outputs compare to the actual values
abw_predict <- abw_data %>% 
  mutate(predict = predict(abw_model))

# create a new dataframe for the next years for which we want to predict
abw_newdata <- data.frame(predict_year = c("2019-11-24", "2020-11-24")) %>%
  mutate(predict_year = as.Date(predict_year, format = "%Y"),
         predict_year = as.factor(predict_year))

class(abw_newdata$predict_year)

# use the predict() function to plug in the year 2019 & 2020

#predict(abw_model, abw_newdata, se.fit = TRUE)
  
  #mutate(predict_fish_eff = predict(abw_model, newdata = predict_year))

#abw_newdata$predict_fishing_hours = predict(abw_model, newdata = abw_newdata)

#predict_fish_eff <- predict(abw_model, abw_newdata)
```
```{r}
# the predict function wasnt working, try using the forecast Arima method

ts_abw <- ts(abw_data$mean_effort)

abw_arima <- arima(ts_abw, order=c(0,1,1))
abw_arima

abw_forecast <- forecast(abw_arima, h=5)
abw_forecast
# this outputs a predicted value of ~67 fishing hours for the next 5 time periods, but this is not exactly what we want, because we want to use a linear model to predict different values for each future year, so either we did not use the right order = c(0,1,1) or we need to just find a way to plug in the next time periods to the linear model we output from the for loop
```

Return to the idea of trying to plug in 1-3 time period increases into the linear model output for each country:

```{r}
# rearraneg the model so that you're taking the summary of the lm model, so the summary is the object abw_model
abw_model = summary(lm(mean_effort ~ year, data = abw_data))
abw_model

#point_est_m_f = model_m_f$coefficients[,"Estimate"]
#SE_m_f = model_m_f$coefficients[,"Std. Error"]

abw_estimates = abw_model$coefficients[,"Estimate"]
abw_estimates[1]
abw_estimates[2]
```


















```{r}
# format the year column for the full loop data to be a date
loop_data <- loop_data %>% 
  mutate(year = as.Date(year, format = "%Y"))
```


```{r loop with years as dates}
# This loop manually combines the intercept and the slope coefficient into a linear equation and prints the predicted fishing hours for that country. The only adjustment I need to make is figuring out how to make the loop run for each country rather than each row.
for (i in 1:length(country)) {
  subset_data <- subset(loop_data, flag_gfw == country[i])
  model_summary <- summary(lm(mean_effort ~ year, data = subset_data))
  print(loop_data$flag_gfw[i])
  print(model_summary$coefficients[,"Estimate"][1])
  print(model_summary$coefficients[,"Estimate"][2])
  print(paste0("In 2 years, the predicted fishing hours for ", loop_data$flag_gfw[i], " is ", (model_summary$coefficients[,"Estimate"][1]) + (model_summary$coefficients[,"Estimate"][2])*(2)))
}
```

```{r}
# try to get the loop to run for each country rather than each row

country = unique(loop_data$flag_gfw)

loop_data_factor = loop_data %>% 
  mutate(flag_gfw = as.factor(flag_gfw))

class(loop_data$flag_gfw)
class(loop_data_factor$flag_gfw)

for (i in 1:length(loop_data_factor)) {
  subset_data <- subset(loop_data, group_by(loop_data_factor$flag_gfw[i]))
  model_summary <- summary(lm(mean_effort ~ year, data = subset_data))
  print(loop_data$flag_gfw[i])
  print(model_summary$coefficients[,"Estimate"][1])
  print(model_summary$coefficients[,"Estimate"][2])
  print(paste0("In 2 years, the predicted fishing hours for ", loop_data$flag_gfw[i], " is ", (model_summary$coefficients[,"Estimate"][1]) + (model_summary$coefficients[,"Estimate"][2])*(1)))
}
```

```{r}
countries_list = split(loop_data, loop_data$flag_gfw)
#countries_list

for (i in 1:length(countries_list)) {
  countries_df[i] <- as.data.frame(countries_list[i])
}

countries_list[2]
class(countries_list[2])

for (i in 1:length(countries_list)) {
  subset_data[i] <- countries_list[i]
  model_summary <- summary(lm(mean_effort ~ year, data = subset_data[i]))
  print(loop_data$flag_gfw[i])
  print(model_summary$coefficients[,"Estimate"][1])
  print(model_summary$coefficients[,"Estimate"][2])
  print(paste0("In 2 years, the predicted fishing hours for ", loop_data$flag_gfw[i], " is ", (model_summary$coefficients[,"Estimate"][1]) + (model_summary$coefficients[,"Estimate"][2])*(2)))
}
```

```{r}
#map(country_list, ~lm(mean_effort ~ year, data = country_list))
```

```{r}
#countries_list_env <- list2env(countries_list, envir = .GlobalEnv)
#countries_list_env[2]
```

```{r}
#countries_df <- lapply(countries_list, as.data.frame(countries_list))
```

```{r}
abw_model

ago_data <- loop_data %>% 
  filter(flag_gfw == "AGO")

ago_model = lm(mean_effort ~ year, data = ago_data)
summary(ago_model)
```


```{r}
models <- sapply(unique(as.character(loop_data$flag_gfw)),
                 function(country)lm(mean_effort~year, loop_data, subset = (flag_gfw == country)),
                 simplify = FALSE, USE.NAMES = TRUE)
models[["ABW"]]
#models[["ABW"]]$coefficients
# to summarize all the models
countries_lm_summaries <- lapply(models, summary)
countries_lm_summaries[1]
abw_summary <- countries_lm_summaries[1]
abw_summary$coefficients[,"Estimate"][2]
```

```{r}
prediction_data = NULL;
for (i in 1:length(countries_lm_summaries)) {
  one_country_summary <- countries_lm_summaries[i]
  print(one_country_summary)
  intercept <- one_country_summary$coefficients[,"Estimate"][1]
  slope <- one_country_summary$coefficients[,"Estimate"][2]
  effort_1_year_after <- intercept + slope*1
  #print(paste0("In 2 years, the predicted fishing hours in 2 years is ", (intercept + slope*2)))
  prediction_data <- rbind(prediction_data, effort_1_year_after)
}
```


## when I was struggling with ttests and decomposition code:

```{r}
# narrow it down to two countries, but the ttest still fails because now there is not enough x observations
ttest_data_chn_fji <- comparison_2020_pos %>% 
  filter(flag_gfw == "CHN" | flag_gfw == "FJI")

ttest = t.test(difference ~ flag_gfw, data = ttest_data_chn_fji, conf.level = 0.95)
```

```{r}
# we only need 1 p-val for countries comparing those that inc or dec fishing, the ID of the country does not matter at this point, so lets make all the countries that inc "INC" and those that dec to "DEC" and run a ttest

ttest_data_inc_dec <- comparison_2020_pos %>% 
  mutate(change_direc = case_when(
    difference > 0 ~ "inc",
    difference <0 ~ "dec"))

ttest = t.test(change_direc ~ flag_gfw, data = ttest_data_inc_dec, conf.level = 0.95)

```


## Consider removing the negative predicted values from the fishing data...they are impossible intercepts
## Consider changing the explanation for filtering for countries from 2017-2020 to train the lm model, the more reasonable reasoning is that 2017-2019 is 3 yrs of data that leads up to 2020, most predictive due to it being recent and it gives more countries than doing 2016-2019 since we have to remove all NA values


Try to look at trend strength in actual 2017-2020 versus trend strength in predicted 2017-2020 using classical_decomposition()

```{r}
# restructure countries_clean data to be by year rather than by country, so getting means from 2017, 2018, 2019, actual 2020, pred 2020

# actual data reconstruction

effort_trends_cd <- data %>% 
  select(flag_gfw, 
         fishing_hours_2012,
         fishing_hours_2013,
         fishing_hours_2014,
         fishing_hours_2015,
         fishing_hours_2016,
         fishing_hours_2017,
         fishing_hours_2018,
         fishing_hours_2019,
         fishing_hours_2020) %>% 
  filter(flag_gfw == "ARG" | flag_gfw == "AUS" | flag_gfw == "BEL" | flag_gfw == "BGR" | flag_gfw == "BLZ" | flag_gfw == "CHN" | flag_gfw == "COL" | flag_gfw == "CUB" | flag_gfw == "CUW" | flag_gfw == "DEU" | flag_gfw == "DNK" | flag_gfw == "ECU" | flag_gfw == "ESP" | flag_gfw == "FIN" | flag_gfw == "FJI" | flag_gfw == "FRA" | flag_gfw == "FRO" | flag_gfw == "FSM" | flag_gfw == "GBR" | flag_gfw == "GRC" | flag_gfw == "HKG" | flag_gfw == "HRV" | flag_gfw == "IRL" | flag_gfw == "IRN" | flag_gfw == "ITA" | flag_gfw == "LBR" | flag_gfw == "LVA" | flag_gfw == "MAR" | flag_gfw == "MEX" | flag_gfw == "MHL" | flag_gfw == "MLT" | flag_gfw == "MYS" | flag_gfw == "NAM" | flag_gfw == "NCL" | flag_gfw == "NIC" | flag_gfw == "NLD" | flag_gfw == "PAN" | flag_gfw == "PHL" | flag_gfw == "POL" | flag_gfw == "PRT" | flag_gfw == "RUS" | flag_gfw == "SLE" | flag_gfw == "SWE" | flag_gfw == "SYC" | flag_gfw == "TUR" | flag_gfw == "TWN" | flag_gfw == "UNK" | flag_gfw == "VEN" | flag_gfw == "VUT" | flag_gfw == "ZAF") %>% 
  summarize("2012" = mean(fishing_hours_2012, na.rm = TRUE),
            "2013" = mean(fishing_hours_2013, na.rm = TRUE),
            "2014" = mean(fishing_hours_2014, na.rm = TRUE),
            "2015" = mean(fishing_hours_2015, na.rm = TRUE),
            "2016" = mean(fishing_hours_2016, na.rm = TRUE),
            "2017" = mean(fishing_hours_2017, na.rm = TRUE),
            "2018" = mean(fishing_hours_2018, na.rm = TRUE),
            "2019" = mean(fishing_hours_2019, na.rm = TRUE),
            "2020" = mean(fishing_hours_2020, na.rm = TRUE))

effort_trends_tidy_no_na_cd_actual = effort_trends_cd %>%
  select("2017":"2020") %>% 
  pivot_longer(cols = ("2017":"2020"),
               names_to = "year",
               values_to = "mean_effort") %>%
  mutate(year = as.Date(year, format = "%Y"))

actual_graph <- ggplot(effort_trends_tidy_no_na_cd_actual, aes(x = year, y = mean_effort)) +
  geom_line()
actual_graph

# remove those countries from the dataframe
# countries_clean_cd_actual <- effort_trends_tidy_no_na_cd_actual %>% 
#   group_by(flag_gfw) %>%
#   #filter(n()>1) %>% 
#   mutate(year = as.Date(year, format = "%Y"))

# for cd, we need to find means by year

#TEST <- aggregate(effort_trends_tidy_no_na_cd_actual$mean_effort, by = list(year=effort_trends_tidy_no_na_cd_actual$year), FUN=mean)

# cd_actual <- effort_trends_tidy_no_na_cd_actual %>%
#   select(year, mean_effort) %>%
#   mutate(year = as.factor(year)) %>%
#   group_by(year) %>%
#   summarize(mean_effort = mean(mean_effort)) #%>%
# mutate(year = as.Date(year, format = "%Y"))
# 
# class(cd_actual$year)

# pred data reconstruction, can use the original effort_trends_tidy_no_na and append the predicted 2020 values

# filter for only countries that were in comparsion_2020_pos
unique(comparison_2020_pos$flag_gfw)

# make all prediction data pos
#prediction_data_pos <- prediction_data %>% 
#  filter(V1 > 0)

summarized_pred_data <- comparison_2020_pos %>% 
  summarize(mean_pred_hours = mean(prediction_2020))

effort_trends_tidy_no_na_cd_predicted <- effort_trends_cd %>%
  select("2017":"2019") %>% 
  cbind(summarized_pred_data$mean_pred_hours) %>% 
  rename("2020" = "summarized_pred_data$mean_pred_hours") %>%
  pivot_longer(cols = ("2017":"2020"),
               names_to = "year",
               values_to = "mean_effort") %>%
  mutate(year = as.Date(year, format = "%Y"))

predicted_graph <- ggplot(effort_trends_tidy_no_na_cd_predicted, aes(x = year, y = mean_effort)) +
  geom_line()
predicted_graph

# countries_clean_cd_pred <- effort_trends_tidy_no_na_cd_predicted %>% 
#   group_by(flag_gfw) %>%
#   #filter(n()>1) %>% 
#   mutate(year = as.Date(year, format = "%Y"))
# 
# cd_pred <- countries_clean_cd_pred %>% 
#   group_by(year) %>% 
#   summarize(mean_effort = mean(mean_effort)) %>% 
#   select(year, mean_effort)

# actual cd

# decomposition_actual <- as_tsibble(effort_trends_tidy_no_na_cd_actual) %>%
#   model(classical_decomposition(mean_effort, type = "additive")) %>%
#   components(x, tread) %>%
#   autoplot() +
#   labs(title = "Classical additive decomposition of average fishing effort by year")
# 
# decomposition_actual

```


## MISC other code that I had tried, just for safe-keeping:

```{r}
# this for loop iterates through the lm summaries of each country, and should put the predicted fishing effort for 2020 into the empty dataframe I create called "prediction_data"

# prediction_data = NULL;
# for (i in 1:length(countries_lm_summaries)) {
#   one_country_summary <- countries_lm_summaries[i]
#   print(one_country_summary)
#   intercept <- one_country_summary$coefficients[,"Estimate"][1]
#   print(intercept)
#   slope <- one_country_summary$coefficients[,"Estimate"][2]
#   print(slope)
#   predicted_effort_2020 <- intercept + slope*3
#   prediction_data <- rbind(prediction_data, predicted_effort_2020)
#   print(paste0("In 2020, the predicted fishing hours is ", predicted_effort_2020))
# }
```

```{r}
# iterate through the models, running lm() on each country
# models <- sapply(unique(as.character(countries_clean$flag_gfw)),
#                  function(country)lm(mean_effort~year, countries_clean, subset = (flag_gfw == country)),
#                  simplify = FALSE, USE.NAMES = TRUE)
# 
# # summarize all the models
# countries_lm_summaries <- lapply(models, summary)
# 
# # call the first model
# arg_summary <- models[["ARG"]]
# # try to extract the coefficients from the model
#arg_summary$coefficients[,"Estimate"][2]
# this fails to return the slope coefficient, it returns NULL
#models[["ARG"]]$coefficients[,"Estimate"][2]
# this fails to return the slope coefficient, it returns NULL

#try calling the coefficients from the output of the summary of all the models
# call the first summary
#countries_lm_summaries[1]
#arg_summary <- countries_lm_summaries[1]
#arg_summary$coefficients[,"Estimate"][2]
# this also returns NULL
#class(arg_summary)

# try using unnest()
#coeff <- sapply(countries_clean$models, function(x) return(coefficients(x)))

#bind_cols(countries_clean, data.frame(t(coeff))) %>% 
#     rename_at(6:8, ~ c("intc",  "coef1",  "coef2")) %>% 
#          distinct(flag_gfw, .keep_all = TRUE)

# try to use the do() function
```



